{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Resumo Machine Learning - PI**\n",
    "\n",
    "## **1. Álgebra Linear**\n",
    "\n",
    "### **1.1 Produto Escalar de Tuplas**\n",
    "\n",
    "O **produto escalar** entre dois vetores (tuplas) é uma operação que multiplica elementos correspondentes e soma os resultados. É fundamental em projeções e cálculos de similaridade.\n",
    "\n",
    "**Fórmula:**\n",
    "\n",
    "$$\n",
    "\\text{produto escalar} = \\sum_{i=1}^{n} a_i \\cdot b_i\n",
    "$$\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1, 2, 3)\n",
    "b = (4, 5, 6)\n",
    "produto = sum(x*y for x, y in zip(a, b))\n",
    "print(f\"Produto escalar: {produto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação:**\n",
    "\n",
    "- O produto escalar pode indicar a similaridade entre vetores.\n",
    "- Se o produto escalar for zero, os vetores são ortogonais (perpendiculares).\n",
    "\n",
    "### **1.2 Multiplicação de Matrizes**\n",
    "\n",
    "A multiplicação de matrizes combina linhas de uma matriz com colunas de outra. É usada para transformar espaços, aplicar modelos lineares, entre outros.\n",
    "\n",
    "**Regra:**\n",
    "\n",
    "- O número de colunas da primeira matriz deve ser igual ao número de linhas da segunda.\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "B = np.array([[5, 6],\n",
    "              [7, 8]])\n",
    "C = np.dot(A, B)\n",
    "print(f\"Matriz resultante:\\n{C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação:**\n",
    "\n",
    "- Cada elemento da matriz resultante é o produto escalar de uma linha de A com uma coluna de B.\n",
    "\n",
    "### **1.3 Combinação Linear**\n",
    "\n",
    "Uma **combinação linear** é a soma de vetores multiplicados por escalares. É a base para conceitos como espaço vetorial e independência linear.\n",
    "\n",
    "**Fórmula:**\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = c_1\\mathbf{v}_1 + c_2\\mathbf{v}_2 + \\dots + c_n\\mathbf{v}_n\n",
    "$$\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([0, 1])\n",
    "coeficientes = [3, 4]\n",
    "resultado = coeficientes[0]*v1 + coeficientes[1]*v2\n",
    "print(f\"Combinação linear: {resultado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação:**\n",
    "\n",
    "- A combinação linear pode gerar qualquer vetor em um espaço se os vetores originais forem linearmente independentes.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Matrizes**\n",
    "\n",
    "### **2.1 Representação de Dados em Matrizes**\n",
    "\n",
    "Em Machine Learning, dados são frequentemente representados como matrizes, onde linhas representam observações e colunas representam features (atributos).\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cada linha é um exemplo, cada coluna é uma feature\n",
    "dados = np.array([\n",
    "    [1.2, 3.5, 5.1],\n",
    "    [2.3, 3.1, 4.8],\n",
    "    [0.8, 2.9, 5.6]\n",
    "])\n",
    "print(\"Dados:\\n\", dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Organização de Problemas como Operações Matriciais**\n",
    "\n",
    "Problemas podem ser formulados em termos de operações matriciais para simplificar cálculos e aproveitar otimizações.\n",
    "\n",
    "**Exemplo:**\n",
    "\n",
    "- Equação normal da regressão linear:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\beta}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Singular Value Decomposition (SVD)**\n",
    "\n",
    "### **Conceito:**\n",
    "\n",
    "SVD é uma fatoração de matrizes que expressa uma matriz **A** como o produto de três matrizes:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^\\top\n",
    "$$\n",
    "\n",
    "- **U** e **V** são matrizes ortogonais.\n",
    "- **Σ** é uma matriz diagonal com os **valores singulares**.\n",
    "\n",
    "### **Interpretação dos Resultados:**\n",
    "\n",
    "- **Redução de Dimensionalidade:** Podemos aproximar a matriz original usando apenas os maiores valores singulares.\n",
    "- **Identificação de Outliers:** Pontos que não são bem representados pelos componentes principais podem ser outliers.\n",
    "\n",
    "**Exemplo: Identificação de Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [2, 4],\n",
    "    [3, 6],\n",
    "    [4, 8],\n",
    "    [100, 200]  # Possível outlier\n",
    "])\n",
    "\n",
    "svd = TruncatedSVD(n_components=1)\n",
    "X_reduzido = svd.fit_transform(X)\n",
    "\n",
    "# Reconstrução\n",
    "X_reconstruido = svd.inverse_transform(X_reduzido)\n",
    "# Erro de reconstrução\n",
    "erro = np.sum((X - X_reconstruido)**2, axis=1)\n",
    "outlier = np.argmax(erro)\n",
    "print(f\"Possível outlier na posição: {outlier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similaridade por Distância Cosseno**\n",
    "\n",
    "- **Distância Cosseno:** Mede o ângulo entre dois vetores.\n",
    "\n",
    "$$\n",
    "\\text{similaridade} = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{\\|\\mathbf{a}\\| \\|\\mathbf{b}\\|}\n",
    "$$\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vetor1 = X_reduzido[0]\n",
    "vetor2 = X_reduzido[1]\n",
    "similaridade = cosine_similarity([vetor1], [vetor2])\n",
    "print(f\"Similaridade cosseno: {similaridade[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **4. Clustering**\n",
    "\n",
    "### **4.1 K-means**\n",
    "\n",
    "**Conceito:**\n",
    "\n",
    "- Agrupa dados em **k** clusters baseados na distância euclidiana.\n",
    "- Iterativamente ajusta os centróides para minimizar a inércia intra-cluster.\n",
    "\n",
    "**Exemplo:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([\n",
    "    [1, 2], [1, 4], [1, 0],\n",
    "    [10, 2], [10, 4], [10, 0]\n",
    "])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "            s=200, c='red', marker='X')\n",
    "plt.title('K-means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Silhouette Score**\n",
    "\n",
    "**Conceito:**\n",
    "\n",
    "- Mede quão similar um ponto é ao seu próprio cluster comparado aos outros clusters.\n",
    "- Varia de -1 a 1; valores próximos a 1 indicam bom ajuste.\n",
    "\n",
    "**Cálculo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(X, labels)\n",
    "print(f\"Silhouette Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação:**\n",
    "\n",
    "- **Alto (>0.5):** Estrutura de cluster definida.\n",
    "- **Médio (0.2 - 0.5):** Estrutura menos clara.\n",
    "- **Baixo (<0.2):** Pode não ser adequado o número de clusters.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Otimização**\n",
    "\n",
    "### **5.1 Mínimo Global vs. Mínimos Locais**\n",
    "\n",
    "- **Mínimo Global:** O ponto mais baixo em toda a função.\n",
    "- **Mínimo Local:** O ponto mais baixo em uma região específica.\n",
    "\n",
    "**Importância:**\n",
    "\n",
    "- Algoritmos podem ficar presos em mínimos locais.\n",
    "- Métodos como inicialização aleatória e otimização estocástica podem ajudar a evitar isso.\n",
    "\n",
    "### **5.2 Gradient Descent**\n",
    "\n",
    "**Conceito:**\n",
    "\n",
    "- Algoritmo para encontrar o mínimo de uma função usando o gradiente (derivada).\n",
    "- Atualiza os parâmetros na direção negativa do gradiente.\n",
    "\n",
    "**Fórmula de Atualização:**\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{novo}} = \\theta_{\\text{atual}} - \\alpha \\nabla J(\\theta)\n",
    "$$\n",
    "\n",
    "Onde:\n",
    "- $\\theta$: Parâmetros\n",
    "- $\\alpha$: Taxa de aprendizado\n",
    "- $\\nabla J(\\theta)$: Gradiente da função de custo\n",
    "\n",
    "**Implementação Guiada:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(derivada, inicial, learning_rate, iteracoes):\n",
    "    x = inicial\n",
    "    for i in range(iteracoes):\n",
    "        grad = derivada(x)\n",
    "        x = x - learning_rate * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise de Comportamento:**\n",
    "\n",
    "- **Mínimos Locais:** Visualize a função para entender onde podem ocorrer.\n",
    "- **Taxa de Aprendizado:** Um valor muito grande pode fazer o algoritmo \"pular\" o mínimo, enquanto um valor muito pequeno torna a convergência lenta.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Regressão Linear**\n",
    "\n",
    "### **Interpretação do Modelo**\n",
    "\n",
    "- **Equação do Modelo:**\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n\n",
    "$$\n",
    "\n",
    "- **Coeficientes ($\\beta$):** Representam o impacto de cada feature na variável target.\n",
    "\n",
    "**Equação Normal:**\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\beta}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "\n",
    "**Interpretação:**\n",
    "\n",
    "- Fornece os coeficientes que minimizam o erro quadrático médio.\n",
    "- **Feature-Peso-Target:** Entender como cada feature influencia o resultado.\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [1, 2100, 3],\n",
    "    [1, 1600, 2],\n",
    "    [1, 2400, 4],\n",
    "    [1, 1416, 2],\n",
    "    [1, 3000, 4]\n",
    "])\n",
    "y = np.array([399900, 329900, 369000, 232000, 539900])\n",
    "\n",
    "# Cálculo dos coeficientes\n",
    "beta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "print(f\"Coeficientes: {beta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **7. Feature Engineering**\n",
    "\n",
    "### **7.1 Polinômios**\n",
    "\n",
    "- **Transformação Polinomial:** Cria novas features elevando as existentes a potências.\n",
    "\n",
    "**Exemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = np.array([[2], [3], [4]])\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "print(\"Features polinomiais:\\n\", X_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicação:**\n",
    "\n",
    "- Permite que modelos lineares capturem relacionamentos não lineares.\n",
    "\n",
    "### **7.2 Outras Transformações**\n",
    "\n",
    "- **Logarítmica:** $\\log(x)$\n",
    "- **Raiz Quadrada:** $\\sqrt{x}$\n",
    "- **One-Hot Encoding:** Para variáveis categóricas.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Aplicação**\n",
    "\n",
    "### **8.1 Análise Exploratória**\n",
    "\n",
    "- **Objetivo:** Entender a distribuição dos dados, detectar outliers e identificar relações.\n",
    "\n",
    "**Passos:**\n",
    "\n",
    "1. **Visualizações:** Histogramas, scatter plots.\n",
    "2. **Estatísticas Descritivas:** Média, mediana, desvio padrão.\n",
    "3. **Correlação:** Matriz de correlação para identificar relações lineares.\n",
    "\n",
    "### **8.2 Construção de Modelo**\n",
    "\n",
    "- **Separação Treino-Teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dados[:, :-1]\n",
    "y = dados[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Modelo Linear com Feature Engineering:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.3 Avaliação de Modelo**\n",
    "\n",
    "- **Medida de Desempenho:** Erro Quadrático Médio (MSE), Coeficiente de Determinação (R²).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_test_poly = poly.transform(X_test)\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretação:**\n",
    "\n",
    "- **MSE Baixo:** Melhor ajuste.\n",
    "- **R² Próximo de 1:** Modelo explica bem a variabilidade dos dados.\n",
    "\n",
    "---\n",
    "\n",
    "## **Dicas Adicionais para a Prova**\n",
    "\n",
    "- **Entenda Conceitos Básicos:** Certifique-se de compreender os fundamentos antes de aprofundar nos detalhes.\n",
    "- **Interpretação é Chave:** Como o professor mencionou, a prova focará na interpretação dos resultados e modelos.\n",
    "- **Pratique Sem Código:** Tente explicar conceitos e resolver problemas sem depender do código para reforçar seu entendimento.\n",
    "- **Relembre Fórmulas Importantes:** Mesmo que o professor forneça as fórmulas, saber como e quando aplicá-las é essencial.\n",
    "- **Foque em Aplicações Práticas:** Pense em como cada técnica é aplicada em problemas reais.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
